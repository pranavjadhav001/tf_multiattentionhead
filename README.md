# MultiAttentionHead module in Tensorflow
implementation of paper : https://arxiv.org/abs/1706.03762

## Requirements
Tensorflow - 2.5.0
numpy - 1.19.5

## References
https://theaisummer.com/attention/
http://jalammar.github.io/illustrated-transformer/
